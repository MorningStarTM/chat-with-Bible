{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader, PDFMinerLoader\n",
    "from constants import CHROMA_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./docs/The Holy Bible NIV.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=500)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\chatLLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(texts, embedding_function, persist_directory=\"./db/\", client_settings=CHROMA_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\chatLLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import base64\n",
    "import textwrap\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from constants import CHROMA_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = \"LaMini-T5-738M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(check_point)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(check_point, device_map=\"auto\", torch_dtype=torch.float32, offload_folder=\"offload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_pipeline():\n",
    "    pipe = pipeline(\n",
    "        'text2text-generation',\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        max_length = 256,\n",
    "        do_sample = True,\n",
    "        temperature = 0.3,\n",
    "        top_p = 0.95\n",
    "    )\n",
    "    local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    return local_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_llm():\n",
    "    llm = llm_pipeline()\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "    db = Chroma(persist_directory='db', embedding_function=embeddings,client_settings=CHROMA_SETTINGS)\n",
    "    retriever = db.as_retriever()\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm = llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_answer(instruction):\n",
    "    response = ''\n",
    "    instruction = instruction\n",
    "    qa = qa_llm()\n",
    "    generated_text = qa(instruction)\n",
    "    answer = generated_text['result']\n",
    "    return answer, generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who is the son of king david?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, metadata = process_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Solomon is the son of King David.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is the Generative Adversarial Networks ?',\n",
       " 'result': 'Generative Adversarial Networks are a class of machine learning techniques that consist of two simultaneously trained models: one (the Generator) trained to generate fake data, and the other (the Discriminator) trained to discern the fake data from real examples.',\n",
       " 'source_documents': [Document(page_content='just three years later, advances in GANs enabled computers to synthesize fake faces\\nwhose quality rivals high-resolution portrait photographs. In this book, we look under\\nthe hood of the algorithm that made all this possible.\\n1.1 What are Generative Adversarial Networks?\\nGenerative Adversarial Networks (GANs)  are a class of machine learning techniques that\\nconsist of two simultaneously trained models: one (the Generator ) trained to generate', metadata={'source': './docs/gans-in-action-deep-learning-with-generative-adversarial-networks.pdf', 'page': 30}),\n",
       "  Document(page_content='the hood of the algorithm that made all this possible.\\n1.1 What are Generative Adversarial Networks?\\nGenerative Adversarial Networks (GANs)  are a class of machine learning techniques that\\nconsist of two simultaneously trained models: one (the Generator ) trained to generate\\nfake data, and the other (the Discriminator ) trained to discern the fake data from real\\nexamples.\\n The word generative  indicates the overall purpose of the model: creating new data.', metadata={'source': './docs/gans-in-action-deep-learning-with-generative-adversarial-networks.pdf', 'page': 30}),\n",
       "  Document(page_content='1.1 What are Generative Adversarial Networks?\\nGenerative Adversarial Networks (GANs)  are a class of machine learning techniques that\\nconsist of two simultaneously trained models: one (the Generator ) trained to generate\\nfake data, and the other (the Discriminator ) trained to discern the fake data from real\\nexamples.\\n The word generative  indicates the overall purpose of the model: creating new data.\\nThe data that a GAN will learn to generate depends on the choice of the training set.', metadata={'source': './docs/gans-in-action-deep-learning-with-generative-adversarial-networks.pdf', 'page': 30}),\n",
       "  Document(page_content='whose quality rivals high-resolution portrait photographs. In this book, we look under\\nthe hood of the algorithm that made all this possible.\\n1.1 What are Generative Adversarial Networks?\\nGenerative Adversarial Networks (GANs)  are a class of machine learning techniques that\\nconsist of two simultaneously trained models: one (the Generator ) trained to generate\\nfake data, and the other (the Discriminator ) trained to discern the fake data from real\\nexamples.', metadata={'source': './docs/gans-in-action-deep-learning-with-generative-adversarial-networks.pdf', 'page': 30})]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
